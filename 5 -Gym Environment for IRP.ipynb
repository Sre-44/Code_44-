{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19715430-63b5-4529-9be2-a1d18f64562f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Spyder Editor\n",
    "\n",
    "This is a temporary script file.\n",
    "\"\"\"\n",
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import geopy.distance\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "#from tabulate import tabulate\n",
    "#from vrplib import read_solution\n",
    "\n",
    "from pyvrp import Model#, read\n",
    "#from pyvrp.plotting import (\n",
    "#    plot_coordinates,\n",
    "#    plot_instance,\n",
    "#    plot_result,\n",
    "#    plot_route_schedule,\n",
    "#)\n",
    "from pyvrp.stop import MaxIterations, MaxRuntime\n",
    "\n",
    "\n",
    "\n",
    "#This is the openAI gym implementation of our assignment.\n",
    "class AI4LEnvironment(gym.Env):\n",
    "    \"\"\"Dynamic Inventory Routing Environment for OpenAI gym\"\"\"\n",
    "    metadata = {'render.modes': ['human']}\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.nStores = 17\n",
    "\n",
    "        self.data = dict()\n",
    "        \n",
    "        ## latitute coordinates; First element is depot\n",
    "        self.lat = np.array([52.4572735973313,\n",
    "                             52.5626752866663,\n",
    "                             52.5524998075759,\n",
    "                             52.5485533897899,\n",
    "                             52.5491337603554,\n",
    "                             52.533031250357,\n",
    "                             52.5326620602486,\n",
    "                             52.5257945584331,\n",
    "                             52.5360673338073,\n",
    "                             52.513899889604,\n",
    "                             52.5006751919937,\n",
    "                             52.4805171338363,\n",
    "                             52.4965099365104,\n",
    "                             52.4921203344399,\n",
    "                             52.4575252353351,\n",
    "                             52.4873876246243,\n",
    "                             52.4976166075393,\n",
    "                             52.4861757546093\n",
    "                             ])\n",
    "        \n",
    "        ## Longitude coordinates, first element is depot\n",
    "        self.lon = np.array([13.3878670887734,\n",
    "                             13.364101495398,\n",
    "                             13.3610115906129,\n",
    "                             13.4127270662978,\n",
    "                             13.4547634845713,\n",
    "                             13.387585268824,\n",
    "                             13.398873880729,\n",
    "                             13.4156247242011,\n",
    "                             13.435584982625,\n",
    "                             13.4691377305421,\n",
    "                             13.4760565571936,\n",
    "                             13.4389650463,\n",
    "                             13.4224855541126,\n",
    "                             13.4226572154896,\n",
    "                             13.3920890219171,\n",
    "                             13.3764057793401,\n",
    "                             13.3456685769195,\n",
    "                             13.3199641186209\n",
    "                             ])\n",
    "        \n",
    "        \n",
    "        self.data['distance_matrix'] = np.zeros(shape = [self.nStores + 1, self.nStores + 1])\n",
    "        \n",
    "        #variable transport cost per unit distance\n",
    "        self.transportCost = 5;\n",
    "        \n",
    "        #fixed transport cost per used route\n",
    "        self.fixedTransportCost = 100;\n",
    "        \n",
    "        \n",
    "        #the distance matrix is in the end the cost matrix. we take the distance\n",
    "        #between coordinates and multiply it with the variable transportCost\n",
    "        for i in range(0, self.nStores + 1):\n",
    "            for j in range(0, self.nStores + 1):\n",
    "                coords_1 = (self.lat[i], self.lon[i])\n",
    "                coords_2 = (self.lat[j], self.lon[j])\n",
    "                \n",
    "                self.data['distance_matrix'][i][j] = geopy.distance.geodesic(coords_1, coords_2).km * self.transportCost\n",
    "                                           \n",
    "                            \n",
    "        # the vehicle capacity, the number of vehicles.\n",
    "        self.data['vehicle_capacity'] = 100\n",
    "        self.data['num_vehicles'] = 17\n",
    "\n",
    "        #Information of the stores (holding cost, lost-sales cost, capacity)\n",
    "        self.c_holding = 1 \n",
    "        self.c_lost    = 10\n",
    "        self.capacity  = 100\n",
    "        \n",
    "        # The maximum to be shipped to a store\n",
    "        self.maxOrderQuantity = 60;\n",
    "                \n",
    "        # the current amount of inventory in each store. The one main warehouse should contain atleast 100,000 qty to withstand all demands.\n",
    "        #So make sure you fill it first-sr\n",
    "        self.inventories = np.zeros(self.nStores + 1)\n",
    "  \n",
    "        self.demandMean = np.array([ 0,\n",
    "                                    ceil(abs(np.random.normal(20,6.5,1))), \n",
    "                                    ceil(abs(np.random.normal(11,4.1,1))), \n",
    "                                    ceil(abs(np.random.normal(19,5.2,1))), \n",
    "                                    ceil(abs(np.random.normal(14,5.3,1))), \n",
    "                                    ceil(abs(np.random.normal(17,6.2,1))), \n",
    "                                    ceil(abs(np.random.normal(14,5.5,1))), \n",
    "                                    ceil(abs(np.random.normal(20,6.4,1))), \n",
    "                                    ceil(abs(np.random.normal(18,5,1))), \n",
    "                                    ceil(abs(np.random.normal(9,2.1,1))), \n",
    "                                    ceil(abs(np.random.normal(16,5.2,1))), \n",
    "                                    ceil(abs(np.random.normal(13,3.6,1))), \n",
    "                                    ceil(abs(np.random.normal(13,3.2,1))), \n",
    "                                    ceil(abs(np.random.normal(16,5.4,1))),\n",
    "                                    ceil(abs(np.random.normal(18,5.6,1))), \n",
    "                                    ceil(abs(np.random.normal(19,5,1))),\n",
    "                                    ceil(abs(np.random.normal(13,4,7,1))), \n",
    "                                    ceil(abs(np.random.normal(11,4,1)))])\n",
    "        \n",
    "        np.random.seed(1331)\n",
    "                \n",
    "        # create some fixed order up to levels. \n",
    "        # THIS IS JUST FOR ILLUSTRATION PURPOSES\n",
    "        self.orderUpTo = np.ceil(self.demandMean + 2)\n",
    "\n",
    "\n",
    "        #For bookkeeping purposes\n",
    "        self.demands = np.zeros(self.nStores + 1)\n",
    "        self.action  = np.zeros(self.nStores + 1)\n",
    "        self.cost    = 0\n",
    "        self.avgCost = 0;\n",
    "        \n",
    "        \n",
    "        \n",
    "        #OPEN AI GYM elements that need to be set\n",
    "        #this should indicate between which values the rewards could fluctuate\n",
    "        # (Your teacher has no real clue what happens with it)\n",
    "        self.reward_range = (self.nStores * -1 * self.capacity * self.c_lost, 3 * self.capacity * self.c_holding)\n",
    "        \n",
    "        # we need to define the shape of an action\n",
    "        # for this example, we set it equal to a simple multibinairy action\n",
    "        # space. (series of zeros and ones for ordering or not)\n",
    "        # It is quite crucial to understand the spaces objects. Please google!\n",
    "\n",
    "        #The action space can vary from low as satisfying the demand-inventories with high as the capacity of each store\n",
    "        self.action_space = spaces.Box(low=self.demandMean - self.inventories, high=self.maxOrderQuantity, shape=(self.nStores+1,),dtype = np.int64)\n",
    "        \n",
    "        # Also note that this action is ignored as we use a base stock\n",
    "        # a first step towards implementation could be to ignore visiting \n",
    "        # a store.\n",
    "        \n",
    "       \n",
    "        # how many stores we will replenish to base stock?\n",
    "\n",
    "        \n",
    "        \n",
    "        #observation space is simply the inventory levels at each store at the\n",
    "        #start of the day #I changed the shape of inventories to self.nstores because I dont see why we need the inventory of main warehouse and now \n",
    "        #the index should start from 1 and not o, because 0 denotes the main warehouse. Main warehouse willhave 17 trucks in the start of any day\n",
    "        self.observation_space = spaces.Box(low = 0, \n",
    "                                            high = self.capacity, \n",
    "                                            shape = (self.nStores + 1,),\n",
    "                                            dtype = np.int64) \n",
    "        self.observation_space = spaces.Dict({\n",
    "            \"demand\": spaces.Box(low=0, high=self.capacity, shape=(self.nStores,), dtype=np.int64),  # Inventory levels\n",
    "            \"units_in_truck\": spaces.Box(low=0, high=100, shape=(1,), dtype=np.int64),  # Units in truck\n",
    "            \"truck_number\": spaces.Box(low=1, high=self.nStores, shape=(1,), dtype=np.int64),  # Truck number\n",
    "            \"remaining_capacity\": spaces.Box(low=0, high=self.capacity, shape=(self.nStores,), dtype=np.int64)  # Remaining capacity after replenishment\n",
    "        })\n",
    "        \n",
    "    \n",
    "    def calcDirectReward(self, action):\n",
    "        \n",
    "               \n",
    "        self.data['demands'] = self.orderUpTo - self.inventories            \n",
    "        \n",
    "        \n",
    "        m = Model()\n",
    "        \n",
    "        int_lat = [int(number * 100) for number in self.lat]\n",
    "        int_lon = [int(number * 100) for number in self.lon]\n",
    "\n",
    "        \n",
    "        depot = m.add_depot(x=int_lat[0], y=int_lon[0])\n",
    "        \n",
    "        clients = [\n",
    "            m.add_client(x= int_lat[idx], y=int_lon[idx], demand=int(self.data['demands'][idx]))\n",
    "            for idx in range(1, len(int_lat))\n",
    "        ]\n",
    "                \n",
    "        locations = [depot] + clients\n",
    "        \n",
    "        m.add_vehicle_type(num_available = self.nStores, capacity = self.data['vehicle_capacity'], fixed_cost = self.fixedTransportCost)\n",
    "        \n",
    "        for idx in range(0, len(self.lat)): \n",
    "            for jdx in range(0, len(self.lat)):\n",
    "                distance = self.data['distance_matrix'][idx][jdx]   # Manhattan\n",
    "                m.add_edge(locations[idx], locations[jdx], distance=distance)\n",
    "     \n",
    "        \n",
    "        \n",
    "     \n",
    "        res = m.solve(stop = MaxRuntime(0.0001))\n",
    "\n",
    "        print(res)\n",
    "     \n",
    "        return -1 * res.cost()\n",
    "\n",
    "\n",
    "        \n",
    "    def step(self, action):\n",
    "        # Execute one time step within the environment\n",
    "        \n",
    "        \n",
    "        reward = self.calcDirectReward(action)\n",
    "\n",
    "        self._take_action(action)\n",
    "        self.current_step += 1\n",
    "        \n",
    "        # generate random demand\n",
    "        demands = np.zeros(self.nStores)\n",
    "        \n",
    "        \n",
    "        for i in range(0, self.nStores):\n",
    "            demands[i] = self.demandMean[i]\n",
    "            self.inventories[i] -= demands[i]\n",
    "            reward -= max(0, self.inventories[i]) * self.c_holding + -1 * min(0, self.inventories[i]) * self.c_lost\n",
    "            \n",
    "            self.inventories[i] = max(0, self.inventories[i])\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.cost += reward\n",
    "        self.avgCost = self.cost / self.current_step\n",
    "        \n",
    "        \n",
    "        done = self.current_step >= 2000\n",
    "        \n",
    "        obs = self._next_observation() \n",
    "\n",
    "        return obs, reward, done, {}\n",
    "    \n",
    "        \n",
    "    def _take_action(self, action):\n",
    "        \n",
    "        #in this example it is rather simple; the inventory is shipped\n",
    "        self.inventories = self.orderUpTo.copy()\n",
    "        \n",
    "        \n",
    "        \n",
    "          \n",
    "    def reset(self):\n",
    "        # Reset the state of the environment to an initial state\n",
    "        self.inventories = np.zeros(self.nStores + 1)\n",
    "                \n",
    "        self.current_step = 0\n",
    "        \n",
    "        \n",
    "        self.cost = 0\n",
    "        self.avgCost = 0;\n",
    "        \n",
    "        return self._next_observation()\n",
    "    \n",
    "    \n",
    "    def _next_observation(self):\n",
    "        return self.inventories\n",
    "        \n",
    "    \n",
    "    def render(self, mode='human', close=False):\n",
    "        print(\"No rendering implemented\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def example(episodes=10):\n",
    "    \n",
    "    env = AI4LEnvironment()\n",
    "    total_rewards = []\n",
    "\n",
    "    for episode in range(episodes):\n",
    "        observation = env.reset()\n",
    "        observation, reward, done, info = env.step(0)\n",
    "        total_rewards.append(reward)\n",
    "      \n",
    "        print(f'Episode {episode + 1}, Total Reward: {reward}')\n",
    "\n",
    "    env.close()\n",
    "    return total_rewards\n",
    "\n",
    "# Train the agent\n",
    "total_rewards = example()\n",
    "\n",
    "# Simple analysis\n",
    "print(f'Average reward: {sum(total_rewards) / len(total_rewards)}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33712819",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
