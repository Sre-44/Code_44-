{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASSIGNMENT 3 - DEEP RL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sb3_contrib import MaskablePPO\n",
    "from sb3_contrib.common.maskable.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "from sb3_contrib.common.maskable.policies import MaskableActorCriticPolicy\n",
    "from sb3_contrib.common.wrappers import ActionMasker\n",
    "from knapsack_env import BoundedKnapsackEnv\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import torch as th\n",
    "from stable_baselines3.common.env_util import make_vec_env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the action mask for Maskable PPO\n",
    "\n",
    "def mask_fn(env: gym.Env) -> np.ndarray:\n",
    "    return env.get_mask()\n",
    "def make_env():\n",
    "    env = BoundedKnapsackEnv(n_items=200, max_weight=200, mask=True)\n",
    "\n",
    "    # Wrapping up the environment on mask function\n",
    "    env = ActionMasker(env, mask_fn)\n",
    "\n",
    "    return env\n",
    "\n",
    "vec_env = make_vec_env(make_env, n_envs=1)\n",
    "\n",
    "# # Wrapping the environment with DummyVecEnv\n",
    "# env = DummyVecEnv([lambda: env])\n",
    "\n",
    "# # # Normalizing the observations and rewards\n",
    "env = VecNormalize(vec_env, norm_obs=True, norm_reward= True, clip_obs= float('inf')) #Clipping done to avoid the error on missing argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Logging to ./ppo_knapsack_tensorboard/maskable\\PPO_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programs\\minconda3\\envs\\syscon\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.action_masks to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.action_masks` for environment variables or `env.get_wrapper_attr('action_masks')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 7.74     |\n",
      "|    ep_rew_mean     | 374      |\n",
      "| time/              |          |\n",
      "|    fps             | 338      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 8.36      |\n",
      "|    ep_rew_mean          | 428       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 222       |\n",
      "|    iterations           | 2         |\n",
      "|    time_elapsed         | 18        |\n",
      "|    total_timesteps      | 4096      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2044988 |\n",
      "|    clip_fraction        | 0.787     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -3.73     |\n",
      "|    explained_variance   | -0.297    |\n",
      "|    learning_rate        | 0.001     |\n",
      "|    loss                 | -0.0824   |\n",
      "|    n_updates            | 15        |\n",
      "|    policy_gradient_loss | -0.131    |\n",
      "|    value_loss           | 0.25      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 9.25       |\n",
      "|    ep_rew_mean          | 516        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 199        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 30         |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.31934384 |\n",
      "|    clip_fraction        | 0.813      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.61      |\n",
      "|    explained_variance   | 0.343      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.0679    |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.13      |\n",
      "|    value_loss           | 0.151      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 9.96      |\n",
      "|    ep_rew_mean          | 576       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 190       |\n",
      "|    iterations           | 4         |\n",
      "|    time_elapsed         | 42        |\n",
      "|    total_timesteps      | 8192      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3439731 |\n",
      "|    clip_fraction        | 0.806     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -3.45     |\n",
      "|    explained_variance   | 0.234     |\n",
      "|    learning_rate        | 0.001     |\n",
      "|    loss                 | -0.111    |\n",
      "|    n_updates            | 45        |\n",
      "|    policy_gradient_loss | -0.125    |\n",
      "|    value_loss           | 0.158     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10.3       |\n",
      "|    ep_rew_mean          | 601        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 185        |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 55         |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37404075 |\n",
      "|    clip_fraction        | 0.806      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.3       |\n",
      "|    explained_variance   | 0.21       |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.0529    |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.123     |\n",
      "|    value_loss           | 0.158      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 11.2       |\n",
      "|    ep_rew_mean          | 692        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 181        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 67         |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.39348054 |\n",
      "|    clip_fraction        | 0.791      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.16      |\n",
      "|    explained_variance   | 0.198      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.0977    |\n",
      "|    n_updates            | 75         |\n",
      "|    policy_gradient_loss | -0.118     |\n",
      "|    value_loss           | 0.145      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 12.7       |\n",
      "|    ep_rew_mean          | 824        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 179        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 79         |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42627186 |\n",
      "|    clip_fraction        | 0.778      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.92      |\n",
      "|    explained_variance   | 0.278      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.136     |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.116     |\n",
      "|    value_loss           | 0.147      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 14.3       |\n",
      "|    ep_rew_mean          | 950        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 177        |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 92         |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.41816914 |\n",
      "|    clip_fraction        | 0.754      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.7       |\n",
      "|    explained_variance   | 0.269      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.0851    |\n",
      "|    n_updates            | 105        |\n",
      "|    policy_gradient_loss | -0.107     |\n",
      "|    value_loss           | 0.146      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 15.3       |\n",
      "|    ep_rew_mean          | 991        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 176        |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 104        |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.41741562 |\n",
      "|    clip_fraction        | 0.751      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.45      |\n",
      "|    explained_variance   | 0.346      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.0815    |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.11      |\n",
      "|    value_loss           | 0.138      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 17.4      |\n",
      "|    ep_rew_mean          | 1.13e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 174       |\n",
      "|    iterations           | 10        |\n",
      "|    time_elapsed         | 117       |\n",
      "|    total_timesteps      | 20480     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4088558 |\n",
      "|    clip_fraction        | 0.72      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -2.24     |\n",
      "|    explained_variance   | 0.39      |\n",
      "|    learning_rate        | 0.001     |\n",
      "|    loss                 | -0.144    |\n",
      "|    n_updates            | 135       |\n",
      "|    policy_gradient_loss | -0.101    |\n",
      "|    value_loss           | 0.131     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 21.4      |\n",
      "|    ep_rew_mean          | 1.39e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 174       |\n",
      "|    iterations           | 11        |\n",
      "|    time_elapsed         | 129       |\n",
      "|    total_timesteps      | 22528     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3525675 |\n",
      "|    clip_fraction        | 0.695     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -2.02     |\n",
      "|    explained_variance   | 0.465     |\n",
      "|    learning_rate        | 0.001     |\n",
      "|    loss                 | -0.106    |\n",
      "|    n_updates            | 150       |\n",
      "|    policy_gradient_loss | -0.0983   |\n",
      "|    value_loss           | 0.134     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 23        |\n",
      "|    ep_rew_mean          | 1.52e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 173       |\n",
      "|    iterations           | 12        |\n",
      "|    time_elapsed         | 141       |\n",
      "|    total_timesteps      | 24576     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3627585 |\n",
      "|    clip_fraction        | 0.666     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.82     |\n",
      "|    explained_variance   | 0.663     |\n",
      "|    learning_rate        | 0.001     |\n",
      "|    loss                 | -0.0367   |\n",
      "|    n_updates            | 165       |\n",
      "|    policy_gradient_loss | -0.0762   |\n",
      "|    value_loss           | 0.0956    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 24.7      |\n",
      "|    ep_rew_mean          | 1.6e+03   |\n",
      "| time/                   |           |\n",
      "|    fps                  | 173       |\n",
      "|    iterations           | 13        |\n",
      "|    time_elapsed         | 153       |\n",
      "|    total_timesteps      | 26624     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3981844 |\n",
      "|    clip_fraction        | 0.668     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.68     |\n",
      "|    explained_variance   | 0.699     |\n",
      "|    learning_rate        | 0.001     |\n",
      "|    loss                 | -0.0733   |\n",
      "|    n_updates            | 180       |\n",
      "|    policy_gradient_loss | -0.0756   |\n",
      "|    value_loss           | 0.071     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 26.9       |\n",
      "|    ep_rew_mean          | 1.77e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 172        |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 166        |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.38508615 |\n",
      "|    clip_fraction        | 0.661      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.6       |\n",
      "|    explained_variance   | 0.781      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.0481    |\n",
      "|    n_updates            | 195        |\n",
      "|    policy_gradient_loss | -0.0779    |\n",
      "|    value_loss           | 0.0698     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30        |\n",
      "|    ep_rew_mean          | 1.95e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 172       |\n",
      "|    iterations           | 15        |\n",
      "|    time_elapsed         | 178       |\n",
      "|    total_timesteps      | 30720     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3363675 |\n",
      "|    clip_fraction        | 0.647     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.54     |\n",
      "|    explained_variance   | 0.85      |\n",
      "|    learning_rate        | 0.001     |\n",
      "|    loss                 | -0.106    |\n",
      "|    n_updates            | 210       |\n",
      "|    policy_gradient_loss | -0.0744   |\n",
      "|    value_loss           | 0.0551    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sb3_contrib.ppo_mask.ppo_mask.MaskablePPO at 0x22b832600d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_kwargs = dict(activation_fn=th.nn.ReLU, net_arch=dict(pi=[128, 128], vf=[128, 128]))\n",
    "\n",
    "model = MaskablePPO(MaskableActorCriticPolicy, env, n_epochs = 15, learning_rate=0.001, batch_size = 32, gamma = 0.99, policy_kwargs= policy_kwargs,  verbose=1, tensorboard_log=\"./ppo_knapsack_tensorboard/maskable\")\n",
    "model.learn(total_timesteps= 30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 2404.0 ± 0.0\n"
     ]
    }
   ],
   "source": [
    "env.training = False # Setting env to unnormalized state\n",
    "env.norm_reward = False\n",
    "\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=100, deterministic= True)\n",
    "print(f\"Mean reward: {mean_reward} ± {std_reward}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decisionai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
